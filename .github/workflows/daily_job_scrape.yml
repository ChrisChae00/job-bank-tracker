name: Daily Job Scrape

on:
  schedule:
    - cron: "10 15 * * *" # Runs daily at 10:10am EST (min, hour, day, month, day of week)
  workflow_dispatch: # Allows manual trigger
  # Triggers on pull requests to main branch
  pull_request:
    branches:
      - main

jobs:
  scrape_jobs:
    runs-on: ubuntu-latest # Runs on latest Ubuntu
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref || 'main' }}
          fetch-depth: 0 # Fetch full history for proper git operations

      # Builds the Docker image
      - name: Build Docker image
        run: docker build -t job-scraper .

      # Run scraper with existing DB mounted into the container
      # This allows incremental scraping and cleaning
      # Run scraper and cleaner in Docker
      # Pass AWS RDS credentials as environment variables
      - name: Run scraper and cleaner in Docker
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        run: |
          docker run --rm \
            -e DB_HOST="$DB_HOST" \
            -e DB_NAME="$DB_NAME" \
            -e DB_USER="$DB_USER" \
            -e DB_PASSWORD="$DB_PASSWORD" \
            -e DB_PORT="5432" \
            job-scraper
